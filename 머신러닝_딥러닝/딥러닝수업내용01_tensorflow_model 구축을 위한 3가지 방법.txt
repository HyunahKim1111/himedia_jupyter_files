딥러닝 - tensorflow_model 구축을 위한 3가지 방법

tensorflow는 구글에서 만든 딥러닝 프로그램. 딥러닝은 인공신경망

Dense는 인공신경망에 층을 주는 것임. 
input_dim=16 들어가는 컬럼 개수, 
activation='relu'활성화 함수는 relu로 사용하겠다. 
분류분석이니까 activation='sigmoid'를 써준거다. 
loss='binary_crossentropy' 에러율이 낮은 것.

epochs=50 50번 역전파하면서 오류치를 낮추는거야. 
batch_size=16 470개의 데이터를 16개씩나눠서 분석하라는 뜻. 
batch_size 전체 데이터셋을 몇번으로 나눌거니? 메모리 문제때문에. 너무 크면 과적합, 작으면 성능에 문제가 있으 수 있어. 컴퓨터 상황 봐서 가능한 크게 잡는 게 좋긴 해.

model.add(Dense(30, input_dim=16, activation='relu')) -->이거 하나가 은닉층이야! 많이 쌓으면 시간, 메모리를 많이 잡아먹는다는 단점. Sequential()에 모델을 쌓기만 하면 돼.

loss='binary_crossentropy' loss에 뭘 넣느냐에 따라서 회귀분석을 할지, 분류분석을 할지 결정할 수 있어. 
예를 들어 loss에 회귀분석을 할 때는 평균 제곱 계열 mean_squared_error를, 분류를 할 때는 binary_crossentropy를 넣는다.

optimizer='adam' 오차를 어떻게 줄일거냐? 대부분 adam을 쓴다.
--------------------------------------------------------------------------------------------------------------------------------
<import 목록들>
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint(## 학습중 loss가 거의 변하지 않을 때 모델 저장,  학습자동중단)




(Dense를 쌓는 것을 네트워크를 만든다고 함.)
1. Sequential  API

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# 딥러닝 신경망 모델 정의
model = Sequential()
model.add(Dense(30, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(60, activation='relu'))
model.add(Dense(30, activation = 'relu'))
model. add(Dense(30, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 신경망 훈련 시 사용할 파라미터 세팅(컴파일링)
model.compile(loss="binary_crossentropy", optimizer="adam", metrics=['accuracy'])

# 모델 훈련
history = model.fit(X_train, y_train, epochs=200, batch_size=40, validation_data=(X_test, y_test))
# 훈련 과정에서 나오는 loss값으 보기 위해서는 그래프에 그려야하는데 그래프에 그리기 위해서 history에 담음.


# 딥러닝 모델 성능평가
딥러닝에서 모델의 정확성을 보는 지표는 loss
보통 loss가 낮으면 accuracy가 올라간다. 하지만 가끔 비례하지 않을 때도 있음.
두 지표간 차이가 있을 경우 loss가 낮은 모델이 우수한 모델

score = model.evaluate(X_test, y_test)
print('test loss', score[0])
print('test accuracy', score[1])

그림그리기
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend(['train','val'])
plt.show()
-------------------------------------------------------------------------------------------------------------

2. Tensorflow Functional API를 이용한 함수형 모델
Sequential API는 단순이 층을 여러개 쌓는 형태라 복잡한 형태의 모델 생성에 한계가 있음.
Functional API는 입력층과 출력층을 사용자가 직접 정의 가능
다중입력(multi-input), 다중 출력(multi-output) 등 복잡한 모델을 정의할 수 있음.
Input(shape=(독립변수 수, ))함수를 정의해야 해: 입력층 정의
이전 층을 다음 층의 입력으로 사용
model()에 입력과 출력 정의

from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model

inputs = Input(shape=(X_train.shape[1], ))
x = Dense(30, activation='relu')(inputs)
x = Dense(60, activation='relu')(x)
x = Dense(15, activation='relu')(x)
x = Dense(1, activation='sigmoid')(x)
model = Model(inputs, x)
model.summary()


## 신경망 훈련 시 사용할 파라미터 세팅
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# 훈련한 거를 history변수에 담아주기(나중에 그래프 그려보려구)
history=model.fit(X_train, y_train, epochs=400, batch_size=100, validation_data=(X_test, y_test))

# 딥러닝 모델 성능평가
score=model.evaluate(X_test, y_test)
print('test_loss', score[0])
print('test_accuracy', score[1])

pred = model.predict(X_test)
pred = pd.DataFrame(pred)
pred = pred[0].apply(lambda x : 1 if x > 0.5 else 0)
print(accuracy_score(y_test, pred))
print(classification_report(y_test, pred))

# 그래프 그리기
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend(['train','val'])
plt.show()

3. Model Subclassing API로 모델 만들기
class 형태의 모델 정의 방법
tf.keras.Model을 상속받아 작성한다.

class Titanic(tf.keras.Model):

    def __init__(self):
        super(Titanic, self).__init__()
        self.dense1 = tf.keras.layers.Dense(30, activation = 'relu')
        self.dense2 = tf.keras.layers.Dense(60, activation = 'relu')
        self.dense3 = tf.keras.layers.Dense(15, activation = 'relu')
        self.classifier = tf.keras.layers.Dense(1, activation='sigmoid')

    def call(self, inputs):
        x = self.dense1(inputs)
        x = self.dense2(x)
        x = self.dense3(x)
        return self.classifier(x)

# 클래스 사용하는 방법은 변수에 넣어주기!!!(클래스 호출 방법)
model = Titanic() 

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

history= model.fit(X_train, y_train, epochs=400, batch_size=100, validation_data=(X_test, y_test))

score=model.evaluate(X_test, y_test)
print('test_loss', score[0])
print('test_accuracy', score[1])
pred = model.predict(X_test)
pred = pd.DataFrame(pred)
pred = pred[0].apply(lambda x: 1 if x > 0.5 else 0)
print(accuracy_score(y_test, pred))
print(classification_report(y_test, pred))

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend(['train', 'val'])
plt.show()

----------------------------------------------------------------------------------------------------------------------------

<딥러닝 신경망 모델 정의할 때>

[분류모델]

1. 이진분류시
  model.add(Dense(1, activation='sigmoid'))

  #컴파일
  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

2. 다중분류
  model.add(Dense(여러개, activation='softmax'))

  #컴파일
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

3. 연속형 변수일 때
  model.add(Dense(1)) --> 마지막에 activation을  쓰지 않아.

  # 컴파일
  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])

-----------------------------------------------------------------------------------------------------------------------------

# 모델 저장하기
model.save('./model(저장경로)/파일이름.hdf5')

# 모델 불러오기
from tensorflow.keras.models import load_model
model3 = load_model('./model(저장경로)/파일이름.hdf5')

# history안에 있는 key값 보기
history.history.keys()

# 데이터 프레임에 history내용 넣어서 확인하기.
result = pd.DataFrame(history.history, columns=history.history.keys())

